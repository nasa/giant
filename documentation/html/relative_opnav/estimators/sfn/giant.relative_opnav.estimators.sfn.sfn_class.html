
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>sfn_class &#8212; GIANT 1.0.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../../../_static/logo.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="copyright" title="Copyright" href="../../../copyright.html" />
    <link rel="next" title="SurfaceFeatureNavigation" href="sfn_class/giant.relative_opnav.estimators.sfn.sfn_class.SurfaceFeatureNavigation.html" />
    <link rel="prev" title="sfn" href="../giant.relative_opnav.estimators.sfn.html" />
   
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../../../index.html">
    <img class="logo" src="../../../_static/logo.png" alt="Logo"/>
    
  </a>
</p>



<p class="blurb">A powerful API for Optical Navigation</p>






<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../installation.html">Installing GIANT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started.html">Getting Started</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../giant.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../giant.html#indices">Indices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../copyright.html">Copyright</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../index.html">Documentation overview</a><ul>
  <li><a href="../../../giant.html">API Reference</a><ul>
  <li><a href="../../../giant.relative_opnav.html">giant.relative_opnav</a><ul>
  <li><a href="../../giant.relative_opnav.estimators.html">estimators</a><ul>
  <li><a href="../giant.relative_opnav.estimators.sfn.html">sfn</a><ul>
      <li>Previous: <a href="../giant.relative_opnav.estimators.sfn.html" title="previous chapter">sfn</a></li>
      <li>Next: <a href="sfn_class/giant.relative_opnav.estimators.sfn.sfn_class.SurfaceFeatureNavigation.html" title="next chapter">SurfaceFeatureNavigation</a></li>
  </ul></li>
  </ul></li>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
              <div class="related top">
                &nbsp;
  <nav id="rellinks">
    <ul>
        <li>
          &larr;
          <a href="../giant.relative_opnav.estimators.sfn.html" title="Previous document">sfn</a>
        </li>
        <li>
          <a href="sfn_class/giant.relative_opnav.estimators.sfn.sfn_class.SurfaceFeatureNavigation.html" title="Next document">SurfaceFeatureNavigation</a>
          &rarr;
        </li>
    </ul>
  </nav>
              </div>
          

          <div class="body" role="main">
            
  <section id="module-giant.relative_opnav.estimators.sfn.sfn_class">
<span id="sfn-class"></span><h1>sfn_class<a class="headerlink" href="#module-giant.relative_opnav.estimators.sfn.sfn_class" title="Permalink to this headline">¶</a></h1>
<p>This module provides the capability to locate surface features from a target in an image using 2D cross-correlation.</p>
<section id="description-of-the-technique">
<h2>Description of the Technique<a class="headerlink" href="#description-of-the-technique" title="Permalink to this headline">¶</a></h2>
<p>When a target grows to the point where we can begin to distinguish individual features on the surface in the images, we
typically consider switching to navigating using these features instead of just the center of figure of the target.
There are a number of reasons for this, including the fact that as the body grows in the field of view and errors in
your shape model can start contributing to larger and larger errors in your center-finding results and the fact that
having multiple observations instead of a single puts a stronger constraint on the location of the camera at each image
allowing us to more accurately estimate the trajectory of the camera through time.</p>
<p>One of the most common ways of extracting observations of each feature is through cross correlation, using a very
similar technique to that describe in <a class="reference internal" href="../giant.relative_opnav.estimators.cross_correlation.html#module-giant.relative_opnav.estimators.cross_correlation" title="giant.relative_opnav.estimators.cross_correlation"><code class="xref py py-mod docutils literal notranslate"><span class="pre">cross_correlation</span></code></a>.  Essentially we render what we think each feature will
look like based on the current knowledge of the relative position and orientation of the camera with respect to each
feature (the features are stored in a special catalogue called a <a class="reference internal" href="surface_features/giant.relative_opnav.estimators.sfn.surface_features.FeatureCatalogue.html#giant.relative_opnav.estimators.sfn.surface_features.FeatureCatalogue" title="giant.relative_opnav.estimators.sfn.surface_features.FeatureCatalogue"><code class="xref py py-class docutils literal notranslate"><span class="pre">FeatureCatalogue</span></code></a>).  We then take the rendered
template and use normalized cross correlation to identify the location of the feature in the image.  After we have
identified the features in the image, we optionally solve a PnP problem to refine our knowledge of the spacecraft state
and then repeat the process to correct any errors in the observations created by errors in our initial state estimates.</p>
<p>In more detail, GIANT implements this using the following steps</p>
<ol class="arabic simple">
<li><p>Identify which features we think should be visible in the image using the <a class="reference internal" href="surface_features/giant.relative_opnav.estimators.sfn.surface_features.FeatureCatalogue.html#giant.relative_opnav.estimators.sfn.surface_features.FeatureCatalogue.feature_finder" title="giant.relative_opnav.estimators.sfn.surface_features.FeatureCatalogue.feature_finder"><code class="xref py py-attr docutils literal notranslate"><span class="pre">FeatureCatalogue.feature_finder</span></code></a></p></li>
<li><p>For each feature we predict should be visible, render the template based on the a priori relative state between the
camera and the feature using a single bounce ray trace and the routines from <a class="reference internal" href="../../../giant.ray_tracer.html#module-giant.ray_tracer" title="giant.ray_tracer"><code class="xref py py-mod docutils literal notranslate"><span class="pre">ray_tracer</span></code></a>.</p></li>
<li><p>Perform 2D normalized cross correlation for every possible alignment between the center of the templates and the
image.  We do this in a search region specified by the user and usually in the spatial domain so that we can include
information about which pixels we want to consider when computing the correlation scores, as described in
<a class="reference internal" href="sfn_correlators/giant.relative_opnav.estimators.sfn.sfn_correlators.sfn_correlator.html#giant.relative_opnav.estimators.sfn.sfn_correlators.sfn_correlator" title="giant.relative_opnav.estimators.sfn.sfn_correlators.sfn_correlator"><code class="xref py py-func docutils literal notranslate"><span class="pre">sfn_correlator()</span></code></a>.</p></li>
<li><p>Locate the peaks of the correlation surfaces (optionally locate the subpixel peak by fitting a 2D quadric to the
correlation surface)</p></li>
<li><p>Correct the located peaks based on the location of the center-of-feature in the template to get the
observed center-of-feature in the image.</p></li>
<li><p>Optionally solve the PnP problem for the best shift/rotation of the feature locations in the camera frame to minimize
the residuals between the predicted feature locations and the observed feature locations.  Once complete, update the
knowledge of the relative position/orientation of the camera with respect to the target and repeat all steps except
this one to correct for errors introduced by a priori state knowledge errors.</p></li>
</ol>
</section>
<section id="tuning">
<h2>Tuning<a class="headerlink" href="#tuning" title="Permalink to this headline">¶</a></h2>
<p>There are a few more tuning options in SFN verses normal cross correlation.  The first, and likely most important
tuning is for identifying potentially visible features in an image.  For this, you actually want to set the
<a class="reference internal" href="surface_features/giant.relative_opnav.estimators.sfn.surface_features.FeatureCatalogue.html#giant.relative_opnav.estimators.sfn.surface_features.FeatureCatalogue.feature_finder" title="giant.relative_opnav.estimators.sfn.surface_features.FeatureCatalogue.feature_finder"><code class="xref py py-attr docutils literal notranslate"><span class="pre">FeatureCatalogue.feature_finder</span></code></a> attribute to be something that will correctly determine which features are
possibly visible (typically to an instance of <a class="reference internal" href="surface_features/giant.relative_opnav.estimators.sfn.surface_features.VisibleFeatureFinder.html#giant.relative_opnav.estimators.sfn.surface_features.VisibleFeatureFinder" title="giant.relative_opnav.estimators.sfn.surface_features.VisibleFeatureFinder"><code class="xref py py-class docutils literal notranslate"><span class="pre">VisibleFeatureFinder</span></code></a>).  We discuss the tuning for the
<a class="reference internal" href="surface_features/giant.relative_opnav.estimators.sfn.surface_features.VisibleFeatureFinder.html#giant.relative_opnav.estimators.sfn.surface_features.VisibleFeatureFinder" title="giant.relative_opnav.estimators.sfn.surface_features.VisibleFeatureFinder"><code class="xref py py-class docutils literal notranslate"><span class="pre">VisibleFeatureFinder</span></code></a> here, though you could concievably use something else if you desired.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 48%" />
<col style="width: 52%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">VisibleFeatureFinder.off_boresight_angle_maximum</span></code></p></td>
<td><p>The maximum angle between the boresight of the camera and the
feature location in the camera frame in degrees.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">VisibleFeatureFinder.gsd_scaling</span></code></p></td>
<td><p>The permissible ratio of the camera ground sample distance to
the feature ground sample distance</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">VisibleFeatureFinder.reflectance_angle_maximum</span></code></p></td>
<td><p>The maximum angle between the viewing vector and the average
normal vector of the feature in degrees.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">VisibleFeatureFinder.incident_angle_maximum</span></code></p></td>
<td><p>The maximum angle between the incoming light vector and the
average feature normal vector in degrees.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">VisibleFeatureFinder.percent_in_fov</span></code></p></td>
<td><p>The percentage of the feature that is in the FOV</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">VisibleFeatureFinder.feature_list</span></code></p></td>
<td><p>A list of feature names to consider</p></td>
</tr>
</tbody>
</table>
<p>When tuning the feature finder you generally are looking to only get features that are likely to actually correlate well
in the image so that you don’t waste time considering features that won’t work for one reason or another.  All of these
parameters can contribute to this, but some of the most important are the <code class="docutils literal notranslate"><span class="pre">gsd_scaling</span></code>, which should typically be
around 2 and the <code class="docutils literal notranslate"><span class="pre">off_boresight_angle_maximum</span></code> which should typically be just a little larger than the half diagonal
field of view of the detector to avoid possibly overflowing values in the projection computation and processing features
that are actually way outside the field of view.  Note that since you set the feature finder on each feature catalogue,
this means that you can have different tunings for different feature catalogues (if you have multiple in a scene).</p>
<p>Next we have the parameters that control the actual rendering/correlation for each feature.  These are the same as for
<a class="reference internal" href="../giant.relative_opnav.estimators.cross_correlation.html#module-giant.relative_opnav.estimators.cross_correlation" title="giant.relative_opnav.estimators.cross_correlation"><code class="xref py py-mod docutils literal notranslate"><span class="pre">cross_correlation</span></code></a>.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 40%" />
<col style="width: 60%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">brdf</span></code></p></td>
<td><p>The bidirectional reflectance distribution function used to compute the
expected illumination of a ray based on the geometry of the scene.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">grid_size</span></code></p></td>
<td><p>The size of the grid to use for subpixel sampling when rendering the
templates</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">peak_finder</span></code></p></td>
<td><p>The function to use to detect the peaks of the correlation surfaces.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">blur</span></code></p></td>
<td><p>A flag specifying whether to blur the correlation surfaces to decrease
high frequency noise before identifying the peak.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">search_region</span></code></p></td>
<td><p>The search region in pixels to restrict the area the peak of
the correlation surfaces is searched for around the a priori predicted
centers for each feature</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">min_corr_score</span></code></p></td>
<td><p>The minimum correlation score to accept as a successful identification.
Correlation scores range from -1 to 1, with 1 indicating perfect
correlation.</p></td>
</tr>
</tbody>
</table>
<p>Of these options, most only make small changes to the results.  The 2 that can occasionally make large changes are
<code class="xref py py-attr docutils literal notranslate"><span class="pre">search_region</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">blur</span></code>.  In general
<code class="xref py py-attr docutils literal notranslate"><span class="pre">search_region</span></code> should be set to a few pixels larger than the expected uncertainty in
the camera/feature relative state. Since we are doing spatial correlation here we typically want this number to be as
small as possible for efficiency while still capturing the actual peak. The <code class="xref py py-attr docutils literal notranslate"><span class="pre">blur</span></code>
attribute can also be used to help avoid mistaken correlation (perhaps were only empty space is aligned).  Finally, the
<code class="xref py py-attr docutils literal notranslate"><span class="pre">min_corr_score</span></code> can generally be left at the default, though if you have a poor a
priori knowledge of either the shape model or the relative position of the features then you may need to decrease this
some.</p>
<p>The last set of tuning parameters to consider are those for the PnP solver.  They are as follows:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 53%" />
<col style="width: 47%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">run_pnp_solver</span></code></p></td>
<td><p>A flag to turn the PnP solver on</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">pnp_ransac_iterations</span></code></p></td>
<td><p>The number of RANSAC iterations to attempt in the PnP
solver</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">second_search_region</span></code></p></td>
<td><p>The search region in pixels to restrict the area the
peak of the correlation surfaces is searched for around
the a priori predicted centers for each feature after
a PnP solution has been done</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">measurement_sigma</span></code></p></td>
<td><p>The uncertainty to assume for each measurement</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">position_sigma</span></code></p></td>
<td><p>The uncertainty to assume in the a priori relative
position vector between the camera and the features in
kilometers</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">attitude_sigma</span></code></p></td>
<td><p>The uncertainty to assume in the a priori relative
orientation between the camera and the features in
degrees</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_sigma</span></code></p></td>
<td><p>The uncertainty to assume in the relative position and
orientation between the camera and the features
(overrides the individual position and attitude sigmas)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">max_lsq_iterations</span></code></p></td>
<td><p>The maximum number of iterations to attempt to converge
in the linearized least squares solution of the PnP
problem</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">lsq_relative_error_tolerance</span></code></p></td>
<td><p>The maximum change in the residuals from one iteration
to the next before we consider the PnP solution
converged</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">lsq_relative_update_tolerance</span></code></p></td>
<td><p>The maximum change in the update vector from one
iteration to the next before we consider the PnP
solution converged.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">cf_results</span></code></p></td>
<td><p>A numpy array specifying the observed center of figure
for each target in the image (for instance from
<a class="reference internal" href="../giant.relative_opnav.estimators.cross_correlation.html#module-giant.relative_opnav.estimators.cross_correlation" title="giant.relative_opnav.estimators.cross_correlation"><code class="xref py py-mod docutils literal notranslate"><span class="pre">cross_correlation</span></code></a>) to use to set the a priori
relative state information between the camera and the
feature catalogue</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">cf_index</span></code></p></td>
<td><p>The mapping of feature catalogue number to column of the
<code class="docutils literal notranslate"><span class="pre">cf_result</span></code> array.</p></td>
</tr>
</tbody>
</table>
<p>All of these options can be important.  First, unless you have very good a priori error, you probably should turn the
PnP solver on.  Because of the way SFN works, errors in your a priori state can lead to somewhat significant errors in
the observed feature locations, and the PnP solver can correct a lot of these errors.  If you do turn the PnP solver on
then the rest of these options become important.  The <code class="docutils literal notranslate"><span class="pre">pnp_ransac_iterations</span></code> should typically be set to something
around 100-200, especially if you expect there to be outliers (which there usually are).  The <code class="docutils literal notranslate"><span class="pre">second_search_distance</span></code>
should be set to capture the expected uncertainty after the PnP solution (typically mostly just the uncertainty in the
camera model and the uncertainty in the feature locations themselves).  Typically something around 5 works well.  The
<code class="docutils literal notranslate"><span class="pre">*_sigma</span></code> attributes control the relative weighting between the a priori state and the observed locations, which can
be important to get a good PnP solution.  The <code class="docutils literal notranslate"><span class="pre">max_lsq_iterations`,</span> <span class="pre">``lsq_relative_error_tolerance</span></code>, and
<code class="docutils literal notranslate"><span class="pre">lsq_relative_update_tolerance</span></code> can play an important role in getting the PnP solver to converge, though the defaults
are generally decent.  Finally, the <code class="docutils literal notranslate"><span class="pre">cf_results</span></code> and <code class="docutils literal notranslate"><span class="pre">cf_index</span></code> can help to decrease errors in the a priori relative
state knowledge, which in some cases can be critical to successfully identifying features.</p>
</section>
<section id="use">
<h2>Use<a class="headerlink" href="#use" title="Permalink to this headline">¶</a></h2>
<p>The class provided in this module is usually not used by the user directly, instead it is usually interfaced with
through the <a class="reference internal" href="../../relnav_class/giant.relative_opnav.relnav_class.RelativeOpNav.html#giant.relative_opnav.relnav_class.RelativeOpNav" title="giant.relative_opnav.relnav_class.RelativeOpNav"><code class="xref py py-class docutils literal notranslate"><span class="pre">RelativeOpNav</span></code></a> class using the identifier <code class="xref py py-attr docutils literal notranslate"><span class="pre">sfn</span></code>.  For more
details on using the <a class="reference internal" href="../../relnav_class/giant.relative_opnav.relnav_class.RelativeOpNav.html#giant.relative_opnav.relnav_class.RelativeOpNav" title="giant.relative_opnav.relnav_class.RelativeOpNav"><code class="xref py py-class docutils literal notranslate"><span class="pre">RelativeOpNav</span></code></a> interface, please refer to the <a class="reference internal" href="../../giant.relative_opnav.relnav_class.html#module-giant.relative_opnav.relnav_class" title="giant.relative_opnav.relnav_class"><code class="xref py py-mod docutils literal notranslate"><span class="pre">relnav_class</span></code></a> documentation.  For
more details on using the technique class directly, as well as a description of the <code class="docutils literal notranslate"><span class="pre">details</span></code> dictionaries produced
by this technique, refer to the following class documentation.</p>
<p>One implementation detail we do want to note is that you should set your <a class="reference internal" href="surface_features/giant.relative_opnav.estimators.sfn.surface_features.FeatureCatalogue.html#giant.relative_opnav.estimators.sfn.surface_features.FeatureCatalogue.feature_finder" title="giant.relative_opnav.estimators.sfn.surface_features.FeatureCatalogue.feature_finder"><code class="xref py py-attr docutils literal notranslate"><span class="pre">FeatureCatalogue.feature_finder</span></code></a> on
your feature catalogue before using this class. For instance, if your catalogue is stored in a file called
<code class="docutils literal notranslate"><span class="pre">'features.pickle'</span></code></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pickle</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">giant.relative_opnav.estimators.sfn.surface_features</span> <span class="kn">import</span> <span class="n">VisibleFeatureFinder</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;features.pickle&#39;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">in_file</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">fc</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">in_file</span><span class="p">)</span>  <span class="c1"># type: VisibleFeatureFinder</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fc</span><span class="o">.</span><span class="n">feature_finder</span> <span class="o">=</span> <span class="n">VisibleFeatureFinder</span><span class="p">(</span><span class="n">fc</span><span class="p">,</span> <span class="n">gsd_scaling</span><span class="o">=</span><span class="mf">2.5</span><span class="p">)</span>
</pre></div>
</div>
</section>
<p class="rubric">Classes</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="sfn_class/giant.relative_opnav.estimators.sfn.sfn_class.SurfaceFeatureNavigation.html#giant.relative_opnav.estimators.sfn.sfn_class.SurfaceFeatureNavigation" title="giant.relative_opnav.estimators.sfn.sfn_class.SurfaceFeatureNavigation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SurfaceFeatureNavigation</span></code></a></p></td>
<td><p>This class implements surface feature navigation using normalized cross correlation template matching for GIANT.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="sfn_class/giant.relative_opnav.estimators.sfn.sfn_class.SurfaceFeatureNavigationOptions.html#giant.relative_opnav.estimators.sfn.sfn_class.SurfaceFeatureNavigationOptions" title="giant.relative_opnav.estimators.sfn.sfn_class.SurfaceFeatureNavigationOptions"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SurfaceFeatureNavigationOptions</span></code></a></p></td>
<td><p>This dataclass serves as one way to control the settings for the <a class="reference internal" href="sfn_class/giant.relative_opnav.estimators.sfn.sfn_class.SurfaceFeatureNavigation.html#giant.relative_opnav.estimators.sfn.sfn_class.SurfaceFeatureNavigation" title="giant.relative_opnav.estimators.sfn.sfn_class.SurfaceFeatureNavigation"><code class="xref py py-class docutils literal notranslate"><span class="pre">SurfaceFeatureNavigation</span></code></a> class.</p></td>
</tr>
</tbody>
</table>
<div class="line-block">
<div class="line"><br /></div>
</div>
</section>


          </div>
              <div class="related bottom">
                &nbsp;
  <nav id="rellinks">
    <ul>
        <li>
          &larr;
          <a href="../giant.relative_opnav.estimators.sfn.html" title="Previous document">sfn</a>
        </li>
        <li>
          <a href="sfn_class/giant.relative_opnav.estimators.sfn.sfn_class.SurfaceFeatureNavigation.html" title="Next document">SurfaceFeatureNavigation</a>
          &rarr;
        </li>
    </ul>
  </nav>
              </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2021 United States Government.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../../../_sources/relative_opnav/estimators/sfn/giant.relative_opnav.estimators.sfn.sfn_class.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>